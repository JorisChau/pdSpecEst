<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Joris Chau" />

<meta name="date" content="2017-06-29" />

<title>Data depth and rank-based tests for HPD matrices</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Data depth and rank-based tests for HPD matrices</h1>
<h4 class="author"><em>Joris Chau</em></h4>
<h4 class="date"><em>2017-06-29</em></h4>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>In second-order stationary multivariate time series analysis, non-degenerate autocovariance matrices or spectral density matrices at the Fourier frequencies are necessarily elements of the space of Hermitian positive definite (HPD) matrices. In <span class="citation">(Chau, Ombao, and von Sachs 2017)</span>, we generalize the classical concept of data depth for Euclidean vectors to <em>manifold</em> data depth for matrix-valued observations in the non-Euclidean space of HPD matrices. Data depth is an important tool in statistical data analysis measuring the <em>depth</em> of a point with respect to a data cloud or probability distribution. In this way, data depth provides a center-to-outward ordering of multivariate data observations, generalizing the notion of a rank for univariate observations.</p>
<p>The proposed data depth measures can be used to characterize central regions or detect outlying observations in samples of HPD matrices, such as collections of covariance or spectral density matrices. The depth functions also provide a practical framework to perform rank-based hypothesis testing for samples of HPD matrices by replacing the usual ranks by their depth-induced counterparts. Other applications of data depth include the construction of confidence regions, clustering, or classification for samples of HPD matrices.</p>
<p>In this vignette we demonstrate the use of the functions <code>pdDepth()</code> and <code>pdRankTests()</code> to compute data depth values of HPD matrix-valued observations and perform rank-based hypothesis testing for samples of HPD matrices.</p>
</div>
<div id="data-depth-of-hpd-matrices-with-pddepth" class="section level2">
<h2>Data depth of HPD matrices with <code>pdDepth()</code></h2>
<p>First, we generate a pointwise random sample of <code>(2,2)</code>-dimensional HPD matrix-valued observations using the exponential map <code>Expm()</code>, with underlying geometric (i.e. Karcher or Fréchet) mean equal to the identity matrix <code>diag(2)</code>. Second, we generate a random sample of sequences (curves) of <code>(2,2)</code>-dimensional HPD matrix-valued observations, with underlying geometric mean curve equal to an array of rescaled identity matrices. We can think of the first sample as a random collection of covariance matrices, and the second sample as a random collection of spectral matrices along frequency.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pdSpecEst)
<span class="kw">set.seed</span>(<span class="dv">100</span>)

## Pointwise random sample
X1 &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">50</span>, <span class="kw">Expm</span>(<span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">E_coeff_inv</span>(<span class="fl">0.5</span> *<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">4</span>)))) 
<span class="kw">str</span>(X1)
<span class="co">#&gt;  cplx [1:2, 1:2, 1:50] 0.7794+0i -0.0314-0.0523i -0.0314+0.0523i ...</span>

## Curve random sample
X2 &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">50</span>, <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">5</span>, function(i) <span class="kw">Expm</span>(i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">T_coeff_inv</span>(<span class="fl">0.5</span> *<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">4</span>), i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>))), <span class="dt">simplify =</span> <span class="st">&quot;array&quot;</span>))
<span class="kw">str</span>(X2)
<span class="co">#&gt;  cplx [1:2, 1:2, 1:5, 1:50] 1.074+0i 0.352+0.147i 0.352-0.147i ...</span></code></pre></div>
<p><strong>Remark:</strong> The internal functions <code>pdSpecEst:::E_coeff_inv()</code> and <code>pdSpecEst:::T_coeff_inv()</code> convert (real-valued) basis components to tangent space elements (Hermitian matrices) using an orthonormal basis of the tangent space as described in <span class="citation">(Chau, Ombao, and von Sachs 2017)</span>.</p>
<p>With <code>pdDepth()</code>, we can compute the data depth of a single HPD matrix (resp. curve of HPD matrices) <code>y</code> with respect to a sample of HPD matrices (resp. sample of curves of HPD matrices) <code>X</code>. For more details and properties of the available manifold depth functions, see <span class="citation">(Chau, Ombao, and von Sachs 2017)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Pointwise depth
<span class="kw">pdDepth</span>(<span class="dt">y =</span> <span class="kw">diag</span>(<span class="dv">2</span>), <span class="dt">X =</span> X1, <span class="dt">method =</span> <span class="st">&quot;gdd&quot;</span>) ## geodesic distance depth
<span class="co">#&gt; [1] 0.4326915</span>
<span class="kw">pdDepth</span>(<span class="dt">y =</span> <span class="kw">diag</span>(<span class="dv">2</span>), <span class="dt">X =</span> X1, <span class="dt">method =</span> <span class="st">&quot;zonoid&quot;</span>) ## manifold zonoid depth
<span class="co">#&gt; [1] 0.7600822</span>
<span class="kw">pdDepth</span>(<span class="dt">y =</span> <span class="kw">diag</span>(<span class="dv">2</span>), <span class="dt">X =</span> X1, <span class="dt">method =</span> <span class="st">&quot;spatial&quot;</span>) ## manifold spatial depth
<span class="co">#&gt; [1] 0.7932682</span>

## Integrated depth 
<span class="kw">pdDepth</span>(<span class="dt">y =</span> <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">5</span>, function(i) i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>), <span class="dt">simplify =</span> <span class="st">&quot;array&quot;</span>), <span class="dt">X =</span> X2, <span class="dt">method =</span> <span class="st">&quot;gdd&quot;</span>) 
<span class="co">#&gt; [1] 0.751167</span>
<span class="kw">pdDepth</span>(<span class="dt">y =</span> <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">5</span>, function(i) i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>), <span class="dt">simplify =</span> <span class="st">&quot;array&quot;</span>), <span class="dt">X =</span> X2, <span class="dt">method =</span> <span class="st">&quot;zonoid&quot;</span>) 
<span class="co">#&gt; [1] 0.8631369</span>
<span class="kw">pdDepth</span>(<span class="dt">y =</span> <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">5</span>, function(i) i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>), <span class="dt">simplify =</span> <span class="st">&quot;array&quot;</span>), <span class="dt">X =</span> X2, <span class="dt">method =</span> <span class="st">&quot;spatial&quot;</span>) 
<span class="co">#&gt; [1] 0.8825155</span></code></pre></div>
<p>We can also compute the data depth of each individual object in <code>X</code> with respect to the sample <code>X</code> itself by leaving the argument <code>y</code> in the function <code>pdDepth()</code> unspecified.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(dd1 &lt;-<span class="st"> </span><span class="kw">pdDepth</span>(<span class="dt">X =</span> X1, <span class="dt">method =</span> <span class="st">&quot;gdd&quot;</span>)) ## pointwise geodesic distance depth
<span class="co">#&gt;  [1] 0.4136872 0.4072360 0.4025387 0.4044413 0.2559378 0.3873209 0.3832640</span>
<span class="co">#&gt;  [8] 0.3002407 0.4034977 0.3358114 0.2597040 0.3120139 0.1967228 0.1876342</span>
<span class="co">#&gt; [15] 0.1922631 0.2483946 0.3696490 0.3386755 0.2068996 0.2058298 0.2020919</span>
<span class="co">#&gt; [22] 0.3757002 0.2523476 0.2142259 0.2864097 0.3353675 0.3192103 0.3354539</span>
<span class="co">#&gt; [29] 0.3210167 0.3004936 0.3990564 0.3107404 0.3665464 0.2987992 0.4306943</span>
<span class="co">#&gt; [36] 0.2448184 0.3170413 0.2921210 0.4100427 0.4292756 0.4257262 0.3645616</span>
<span class="co">#&gt; [43] 0.3668837 0.2471900 0.2340217 0.3391741 0.3632063 0.3623502 0.2293419</span>
<span class="co">#&gt; [50] 0.2719987</span>

(dd2 &lt;-<span class="st"> </span><span class="kw">pdDepth</span>(<span class="dt">X =</span> X2, <span class="dt">method =</span> <span class="st">&quot;gdd&quot;</span>)) ## integrated geodesic distance depth
<span class="co">#&gt;  [1] 0.7001805 0.6885243 0.5746611 0.7066090 0.6931021 0.6423633 0.6738678</span>
<span class="co">#&gt;  [8] 0.6197673 0.5654389 0.7123940 0.6469901 0.7158848 0.6487223 0.6243373</span>
<span class="co">#&gt; [15] 0.7075508 0.6356606 0.6654029 0.7162644 0.6380360 0.7091247 0.6595957</span>
<span class="co">#&gt; [22] 0.6520224 0.6627836 0.6932087 0.6783008 0.6798760 0.6490358 0.7024616</span>
<span class="co">#&gt; [29] 0.6324775 0.6889687 0.6728189 0.6927310 0.6464986 0.6492694 0.6591718</span>
<span class="co">#&gt; [36] 0.6874394 0.6743475 0.6365783 0.6644634 0.7112869 0.6935939 0.7361826</span>
<span class="co">#&gt; [43] 0.7209363 0.6161036 0.6952725 0.6470956 0.6250286 0.7059682 0.7125312</span>
<span class="co">#&gt; [50] 0.7113942</span></code></pre></div>
<p>A center-to-outwards ordering of the individual objects is then obtained by computing the data depth induced ranks, with the most central observation having smallest rank and the most outlying observation having largest rank.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(dd1.ranks &lt;-<span class="st"> </span><span class="kw">rank</span>(<span class="dv">1</span> -<span class="st"> </span>dd1)) ## pointwise depth ranks
<span class="co">#&gt;  [1]  4  6  9  7 37 11 12 31  8 22 36 28 48 50 49 39 14 21 45 46 47 13 38</span>
<span class="co">#&gt; [24] 44 34 24 26 23 25 30 10 29 16 32  1 41 27 33  5  2  3 17 15 40 42 20</span>
<span class="co">#&gt; [47] 18 19 43 35</span>

(dd2.ranks &lt;-<span class="st"> </span><span class="kw">rank</span>(<span class="dv">1</span> -<span class="st"> </span>dd2)) ## integrated depth ranks
<span class="co">#&gt;  [1] 14 21 49 11 18 40 26 47 50  6 38  4 36 46 10 43 28  3 41  9 31 33 30</span>
<span class="co">#&gt; [24] 17 24 23 35 13 44 20 27 19 39 34 32 22 25 42 29  8 16  1  2 48 15 37</span>
<span class="co">#&gt; [47] 45 12  5  7</span>

## Explore sample X1
<span class="kw">head</span>(<span class="kw">order</span>(dd1.ranks)) ## most central observations 
<span class="co">#&gt; [1] 35 40 41  1 39  2</span>
<span class="kw">rev</span>(<span class="kw">tail</span>(<span class="kw">order</span>(dd1.ranks))) ## most outlying observations
<span class="co">#&gt; [1] 14 15 13 21 20 19</span>
X1[ , , <span class="kw">which</span>(dd1.ranks ==<span class="st"> </span><span class="dv">1</span>)] ## most central HPD matrix 
<span class="co">#&gt;                       [,1]                  [,2]</span>
<span class="co">#&gt; [1,]  0.9407902+0.0000000i -0.0154483+0.1752587i</span>
<span class="co">#&gt; [2,] -0.0154483-0.1752587i  1.2710700+0.0000000i</span>
X1[ , , <span class="kw">which</span>(dd1.ranks ==<span class="st"> </span><span class="dv">50</span>)] ## most outlying HPD matrix
<span class="co">#&gt;                     [,1]                [,2]</span>
<span class="co">#&gt; [1,]  1.847918+0.000000i -1.288255+1.075924i</span>
<span class="co">#&gt; [2,] -1.288255-1.075924i  2.490724+0.000000i</span></code></pre></div>
<p>It is interesting to compare the most central HPD matrix above with the (approximate) empirical geometric mean of the observations obtained with <code>KarchMean()</code>. The empirical geometric mean is known to maximize the data depth for observations from a <em>centrally symmetric</em> distribution (as in this example). For more details, see <span class="citation">(Chau, Ombao, and von Sachs 2017)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(mean.X1 &lt;-<span class="st"> </span><span class="kw">KarchMean</span>(X1)) 
<span class="co">#&gt;                         [,1]                    [,2]</span>
<span class="co">#&gt; [1,]  0.92208421+0.00000000i -0.04690471+0.02281304i</span>
<span class="co">#&gt; [2,] -0.04690471-0.02281304i  1.14165705+0.00000000i</span>

<span class="kw">pdDepth</span>(<span class="dt">y =</span> mean.X1, <span class="dt">X =</span> X1, <span class="dt">method =</span> <span class="st">&quot;gdd&quot;</span>)
<span class="co">#&gt; [1] 0.4407462</span></code></pre></div>
</div>
<div id="rank-based-tests-for-hpd-matrices-with-pdranktests" class="section level2">
<h2>Rank-based tests for HPD matrices with <code>pdRankTests()</code></h2>
<p>The null hypotheses of the available rank-based hypothesis tests in <code>pdRankTests()</code> are:</p>
<ul>
<li><code>&quot;rank.sum&quot;</code>: homogeneity of distributions of two independent samples of HPD matrices (resp. sequences of HPD matrices).</li>
<li><code>&quot;krusk.wall&quot;</code>: homogeneity of distributions of more than two independent samples of HPD matrices (resp. sequences of HPD matrices).</li>
<li><code>&quot;signed-rank&quot;</code>: homogeneity of distributions of independent paired or matched samples of HPD matrices.</li>
<li><code>&quot;bartels&quot;</code>: exchangeability (i.e. randomness) within a single independent sample of HPD matrices (resp. sequences of HPD matrices).</li>
</ul>
<p>Below, we construct several simulated examples for which (i) the null hypotheses listed above are satisfied, and (ii) the null hypotheses listed above are not satisfied. Analogous to the previous section, we generate pointwise random samples (resp. random samples of sequences) of <code>(2,2)</code>-dimensional HPD matrix-valued observations, with underlying geometric mean equal to the identity matrix (resp. sequence of scaled identity matrices).</p>
<p>Let us first consider simulated examples of the manifold Wilcoxon rank-sum test (<code>&quot;rank.sum&quot;</code>) and manifold Kruskal-Wallis test (<code>&quot;krusk.wall&quot;</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Generate data (null true)
data1 &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">c</span>(X1, <span class="kw">replicate</span>(<span class="dv">50</span>, <span class="kw">Expm</span>(<span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">E_coeff_inv</span>(<span class="fl">0.5</span> *<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">4</span>))))), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">100</span>)) ## pointwise sample
data2 &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">c</span>(X2, <span class="kw">replicate</span>(<span class="dv">50</span>, <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">5</span>, function(i) <span class="kw">Expm</span>(i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">T_coeff_inv</span>(<span class="fl">0.5</span> *<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">4</span>), i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>))), <span class="dt">simplify =</span> <span class="st">&quot;array&quot;</span>))), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">100</span>)) ## curve sample

## Generate data (null false)
data1a &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">c</span>(X1, <span class="kw">replicate</span>(<span class="dv">50</span>, <span class="kw">Expm</span>(<span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">E_coeff_inv</span>(<span class="kw">rnorm</span>(<span class="dv">4</span>))))), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">100</span>)) ## pointwise scale change
data2a &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">c</span>(X2, <span class="kw">replicate</span>(<span class="dv">50</span>, <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">5</span>, function(i) <span class="kw">Expm</span>(i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">T_coeff_inv</span>(<span class="kw">rnorm</span>(<span class="dv">4</span>), i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>))), <span class="dt">simplify =</span> <span class="st">&quot;arra&quot;</span>))), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">100</span>)) ## curve scale change

## Rank-sum test
<span class="kw">pdRankTests</span>(data1, <span class="dt">sample.sizes =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">50</span>), <span class="st">&quot;rank.sum&quot;</span>)[<span class="dv">1</span>:<span class="dv">4</span>] ## null true (pointwise)
<span class="co">#&gt; $test</span>
<span class="co">#&gt; [1] &quot;Manifold Wilcoxon rank-sum&quot;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.1037495</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $statistic</span>
<span class="co">#&gt; [1] 1.626941</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $null.distr</span>
<span class="co">#&gt; [1] &quot;Standard normal distribution&quot;</span>
<span class="kw">pdRankTests</span>(data2, <span class="dt">sample.sizes =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">50</span>), <span class="st">&quot;rank.sum&quot;</span>)[<span class="dv">2</span>] ## null true (curve)
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.9834998</span>
<span class="kw">pdRankTests</span>(data1a, <span class="dt">sample.sizes =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">50</span>), <span class="st">&quot;rank.sum&quot;</span>)[<span class="dv">2</span>] ## null false (pointwise)
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 6.958285e-11</span>
<span class="kw">pdRankTests</span>(data2a, <span class="dt">sample.sizes =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">50</span>), <span class="st">&quot;rank.sum&quot;</span>)[<span class="dv">2</span>] ## null false (curve)
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 1.020181e-15</span>

## Kruskal-Wallis test
<span class="kw">pdRankTests</span>(data1, <span class="dt">sample.sizes =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">25</span>, <span class="dv">25</span>), <span class="st">&quot;krusk.wall&quot;</span>)[<span class="dv">1</span>:<span class="dv">4</span>] ## null true (pointwise)
<span class="co">#&gt; $test</span>
<span class="co">#&gt; [1] &quot;Manifold Kruskal-Wallis&quot;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.1443239</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $statistic</span>
<span class="co">#&gt; [1] 3.87139</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $null.distr</span>
<span class="co">#&gt; [1] &quot;Chi-squared distribution (df = 2)&quot;</span>
<span class="kw">pdRankTests</span>(data2, <span class="dt">sample.sizes =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">25</span>, <span class="dv">25</span>), <span class="st">&quot;krusk.wall&quot;</span>)[<span class="dv">2</span>] ## null true (curve)
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.1526552</span>
<span class="kw">pdRankTests</span>(data1a, <span class="dt">sample.sizes =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">25</span>, <span class="dv">25</span>), <span class="st">&quot;krusk.wall&quot;</span>)[<span class="dv">2</span>] ## null false (pointwise)
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 5.495634e-10</span>
<span class="kw">pdRankTests</span>(data2a, <span class="dt">sample.sizes =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">25</span>, <span class="dv">25</span>), <span class="st">&quot;krusk.wall&quot;</span>)[<span class="dv">2</span>] ## null false (curve)
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 1.033775e-14</span></code></pre></div>
<p>Second, let us consider several examples of the manifold Wilcoxon signed-rank test (<code>&quot;signed-rank&quot;</code>). We generate paired observations for independent trials (or subjects) by introducing trial-specific random effects, such that the paired observations in each trial share a trial-specific geometric mean. Note that for such data the manifold Wilcoxon rank-sum test is no longer valid due to the introduced sample dependence.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Trial-specific means
mu &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">50</span>, <span class="kw">Expm</span>(<span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">E_coeff_inv</span>(<span class="fl">0.1</span> *<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">4</span>))))

## Generate paired samples X,Y
make_sample &lt;-<span class="st"> </span>function(null) <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">50</span>, function(i) <span class="kw">Expm</span>(mu[, , i], pdSpecEst:::<span class="kw">T_coeff_inv</span>(<span class="kw">ifelse</span>(null, <span class="dv">1</span>, <span class="fl">0.5</span>) *<span class="st"> </span><span class="kw">rexp</span>(<span class="dv">4</span>) -<span class="st"> </span><span class="dv">1</span>, mu[, , i])), <span class="dt">simplify =</span> <span class="st">&quot;array&quot;</span>) 

X3 &lt;-<span class="st"> </span><span class="kw">make_sample</span>(<span class="dt">null =</span> T)
Y3 &lt;-<span class="st"> </span><span class="kw">make_sample</span>(<span class="dt">null =</span> T) ## null true
Y3a &lt;-<span class="st"> </span><span class="kw">make_sample</span>(<span class="dt">null =</span> F) ## null false (scale change)

## Signed-rank test
<span class="kw">pdRankTests</span>(<span class="kw">array</span>(<span class="kw">c</span>(X3, Y3), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">100</span>)), <span class="dt">test =</span> <span class="st">&quot;signed.rank&quot;</span>)[<span class="dv">1</span>:<span class="dv">4</span>] ## null true
<span class="co">#&gt; $test</span>
<span class="co">#&gt; [1] &quot;Manifold Wilcoxon signed-rank&quot;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.2025809</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $statistic</span>
<span class="co">#&gt;   V </span>
<span class="co">#&gt; 505 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $null.distr</span>
<span class="co">#&gt; [1] &quot;Wilcoxon signed rank test with continuity correction&quot;</span>
<span class="kw">pdRankTests</span>(<span class="kw">array</span>(<span class="kw">c</span>(X3, Y3a), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">100</span>)), <span class="dt">test =</span> <span class="st">&quot;signed.rank&quot;</span>)[<span class="dv">2</span>] ## null false
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.001444632</span></code></pre></div>
<p>The manifold signed-rank test also provides a valid procedure to test for equivalence of spectral matrices of two (independent) multivariate stationary time series based on the HPD periodogram matrices obtained via <code>pdPgram()</code> as illustrated below. In contrast to other available tests in the literature, this asymptotic test does not require consistent spectral estimators or resampling/bootstrapping of test statistics, and therefore remains computationally efficient for higher-dimensional spectral matrices or a large number of sampled Fourier frequencies.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Signed-rank test for equivalence of spectra
## ARMA(1,1) process: Example 11.4.1 in (Brockwell and Davis, 1991)
Phi &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">c</span>(<span class="fl">0.7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.6</span>, <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">4</span>)), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>))
Theta &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, -<span class="fl">0.7</span>, <span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">4</span>)), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>))
Sigma &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">0.71</span>, <span class="fl">0.71</span>, <span class="dv">2</span>), <span class="dt">nrow =</span> <span class="dv">2</span>)
pgram &lt;-<span class="st"> </span>function(Sigma) <span class="kw">pdPgram</span>(<span class="kw">rARMA</span>(<span class="dv">2</span>^<span class="dv">9</span>, <span class="dv">2</span>, Phi, Theta, Sigma)$X)$P ## HPD periodogram

## Null is true
<span class="kw">pdRankTests</span>(<span class="kw">array</span>(<span class="kw">c</span>(<span class="kw">pgram</span>(Sigma), <span class="kw">pgram</span>(Sigma)), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>^<span class="dv">8</span>)), <span class="dt">test =</span> <span class="st">&quot;signed.rank&quot;</span>)[<span class="dv">2</span>]
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.4045394</span>

## Null is false
<span class="kw">pdRankTests</span>(<span class="kw">array</span>(<span class="kw">c</span>(<span class="kw">pgram</span>(Sigma), <span class="kw">pgram</span>(<span class="fl">0.5</span> *<span class="st"> </span>Sigma)), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>^<span class="dv">8</span>)), <span class="dt">test =</span> <span class="st">&quot;signed.rank&quot;</span>)[<span class="dv">2</span>]
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 5.058065e-14</span></code></pre></div>
<p>To conclude, let us consider several examples of the manifold Bartels-von Neumman test (<code>&quot;bartels&quot;</code>). Below, we generate an independent sample with a gradual trend in the scale of the distribution, such that the null hypothesis of randomness breaks down.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Null is true
data3 &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">200</span>, <span class="kw">Expm</span>(<span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">E_coeff_inv</span>(<span class="kw">rnorm</span>(<span class="dv">4</span>)))) ## pointwise samples
data4 &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">100</span>, <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">5</span>, function(i) <span class="kw">Expm</span>(i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">T_coeff_inv</span>(<span class="kw">rnorm</span>(<span class="dv">4</span>), i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>))), <span class="dt">simplify =</span> <span class="st">&quot;array&quot;</span>)) ## curve samples

## Null is false
data3a &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">200</span>, function(j) <span class="kw">Expm</span>(<span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">E_coeff_inv</span>(((<span class="dv">200</span> -<span class="st"> </span>j) /<span class="st"> </span><span class="dv">200</span> +<span class="st"> </span>j *<span class="st"> </span><span class="dv">2</span> /<span class="st"> </span><span class="dv">200</span>) *<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">4</span>))), <span class="dt">simplify =</span> <span class="st">&quot;array&quot;</span>) ## pointwise trend in scale
data4a &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">100</span>, function(j) <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="dv">5</span>, function(i) <span class="kw">Expm</span>(i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>), pdSpecEst:::<span class="kw">T_coeff_inv</span>(((<span class="dv">100</span> -<span class="st"> </span>j) /<span class="st"> </span><span class="dv">100</span> +<span class="st"> </span>j *<span class="st"> </span><span class="dv">2</span> /<span class="st"> </span><span class="dv">100</span>) *<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">4</span>), i *<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>))), <span class="dt">simplify =</span> <span class="st">&quot;array&quot;</span>), <span class="dt">simplify =</span> <span class="st">&quot;array&quot;</span>) ## curve trend in scale

## Bartels-von Neumann test
<span class="kw">pdRankTests</span>(data3, <span class="dt">test =</span> <span class="st">&quot;bartels&quot;</span>)[<span class="dv">1</span>:<span class="dv">4</span>] ## null true (pointwise)
<span class="co">#&gt; $test</span>
<span class="co">#&gt; [1] &quot;Manifold Bartels-von Neumann&quot;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.8931316</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $statistic</span>
<span class="co">#&gt; [1] 0.1343427</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $null.distr</span>
<span class="co">#&gt; [1] &quot;Standard normal distribution&quot;</span>
<span class="kw">pdRankTests</span>(data4, <span class="dt">test =</span> <span class="st">&quot;bartels&quot;</span>)[<span class="dv">2</span>] ## null true (curve)
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.260438</span>
<span class="kw">pdRankTests</span>(data3a, <span class="dt">test =</span> <span class="st">&quot;bartels&quot;</span>)[<span class="dv">2</span>] ## null false (pointwise)
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.0005847046</span>
<span class="kw">pdRankTests</span>(data4a, <span class="dt">test =</span> <span class="st">&quot;bartels&quot;</span>)[<span class="dv">2</span>] ## null false (curve)
<span class="co">#&gt; $p.value</span>
<span class="co">#&gt; [1] 0.0001358793</span></code></pre></div>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-COvS17">
<p>Chau, J., H. Ombao, and R. von Sachs. 2017. “Data Depth and Rank-Based Tests for Covariance and Spectral Density Matrices.” <a href="http://arxiv.org/abs/1706.08289" class="uri">http://arxiv.org/abs/1706.08289</a>.</p>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
